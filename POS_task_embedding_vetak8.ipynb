{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"Копия блокнота \"POS_task_embedding.ipynb\"\"","provenance":[{"file_id":"127GjmxZ7WqHOxM6nXMaMy-j8A2FTcQJp","timestamp":1625021993616},{"file_id":"1H143EMQrifO-I8lL6JdKiArOmEVGb7os","timestamp":1625021934719}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hsP7cV1_arhs"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torchtext import datasets\n","\n","import numpy as np\n","from sklearn.metrics import classification_report\n","\n","import random\n","\n","from gensim.models import FastText\n","from nltk.stem import PorterStemmer\n","from sklearn.metrics import accuracy_score, f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNRfW260a3jg"},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyk3BCHza5ru"},"source":["train_data, _, test_data = datasets.UDPOS()\n","train_data = [d for d in train_data]\n","test_data = [d for d in test_data]\n","\n","train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n","train_tags = [ d[1] for d in train_data]\n","\n","test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n","test_tags = [d[1] for d in test_data]\n","\n","tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBDDAUdhbxCq"},"source":["stemmer = PorterStemmer()\n","\n","word_to_ix = {}\n","for tokens in train_tokens:\n","    for word in tokens:\n","        word = stemmer.stem(word)\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","\n","word_to_ix[\"UNK\"] =  len(word_to_ix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hkWDYVab5PT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021812361,"user_tz":-180,"elapsed":3215,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"a6dd1eda-f7de-4b77-9ff7-196481b42df2"},"source":["max_len = 20\n","pad_inds = len(tag2num)\n","\n","def prepare_sequence(seq, to_ix):\n","    stemmer = PorterStemmer()\n","    stemmed_words = [stemmer.stem(w) for w in seq]\n","    idxs = [to_ix[w] if w in to_ix else to_ix[\"UNK\"] for w in stemmed_words ]\n","    return torch.tensor(idxs, dtype=torch.long)\n","\n","\n","def prepare_data_for_inner_embeddings(all_tokens, all_tags, word_to_ix, tag2num, max_len, pad_tags):\n","    all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n","    \n","    all_tokens = [tokens[:max_len] for tokens in all_tokens]\n","    all_tags = [tags[:max_len] for tags in all_tags]\n","    \n","    all_ids = []\n","    for tokens in all_tokens:\n","        ids = prepare_sequence(tokens, word_to_ix)\n","        all_ids.append(ids)\n","        \n","    X_vecs = []\n","    Y_vecs = []\n","\n","    for ids, tags in zip(all_ids, all_tags):\n","        X_vecs.append(torch.tensor(ids, dtype=torch.long))\n","        Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n","        \n","    # в качестве заполнителя X используем новый индекс len(word_to_ix)\n","    X = pad_sequence(X_vecs, batch_first=True, padding_value=len(word_to_ix))\n","\n","    # в качестве заполнителя Y используем pad_tags\n","    Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n","    \n","    return X, Y\n","\n","X_train, Y_train = prepare_data_for_inner_embeddings(train_tokens, train_tags, word_to_ix, tag2num, max_len, pad_inds)\n","\n","X_train.size(), Y_train.size()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([12543, 20]), torch.Size([12543, 20]))"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"GYNHAQxZcHhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021812779,"user_tz":-180,"elapsed":37,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"dce621fd-a79a-42a7-dada-f457515b96cd"},"source":["X_test, Y_test = prepare_data_for_inner_embeddings(test_tokens, test_tags, word_to_ix, tag2num, max_len, pad_inds)\n","\n","X_test.size(), Y_test.size()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2077, 20]), torch.Size([2077, 20]))"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"UeBb8AbNcdX_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021812781,"user_tz":-180,"elapsed":34,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"df03aab8-5707-4d4d-ccfc-799dea8b041c"},"source":["print(X_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[    0,     1,     2,  ...,    14,    15,    11],\n","        [   23,    24,     6,  ...,    37, 12121, 12121],\n","        [   38,     3,    39,  ..., 12121, 12121, 12121],\n","        ...,\n","        [ 3083,    43,    28,  ...,   211,    29,    25],\n","        [   11,  4206,    13,  ...,    17,   368,    42],\n","        [  112,    28,   387,  ...,   132,    43,  1054]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GfjixGEdceuN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021812785,"user_tz":-180,"elapsed":33,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"820276ea-bc11-4432-ac73-b1eca0e344cb"},"source":["print(Y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[11, 12, 11,  ...,  7,  1,  5],\n","        [12,  5,  7,  ..., 12, 17, 17],\n","        [11, 12,  0,  ..., 17, 17, 17],\n","        ...,\n","        [ 2, 10,  3,  ...,  2,  3,  5],\n","        [ 5,  7,  1,  ...,  1,  7, 10],\n","        [10,  3,  2,  ...,  7, 10,  2]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W8RSqbmOckWA"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","bs = 128\n","data = TensorDataset(X_train, Y_train)\n","dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5lgGR7Dcl0X"},"source":["class BiLSTMPOSTagger(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        # padding_idx=pad_idx - это номер id \"заполнителя\". \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n","        \n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","        outputs, (hidden, cell) = self.lstm(self.embedding(text))\n","        predictions = self.fc(self.dropout(outputs))\n","        return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHtLZSe8dBWV"},"source":["def train_on_epoch(model, dataloader, optimizer):\n","    model.train()\n","    for batch in dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input, b_tags = batch\n","        \n","        model.zero_grad()\n","        outputs = model(b_input)  \n","\n","        # outputs = [batch size, sent len, out dim]\n","        outputs = outputs.view(-1, outputs.shape[-1])       \n","        # outputs = [batch size * sent len, out dim]\n","\n","        # b_tags = [batch size, sent len]\n","        b_tags = b_tags.view(-1)\n","        # b_tags = [batch size * sent len]\n","        \n","        loss = criterion(outputs, b_tags)\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","def predict_on_dataloader(model, dataloaded):\n","    model.eval()\n","        \n","    all_outputs = []\n","    all_tags = []\n","    for batch in dataloaded:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input, b_tags = batch\n","        outputs = model(b_input)  \n","        \n","        outputs = outputs.view(-1, outputs.shape[-1])       \n","        b_tags = b_tags.view(-1)\n","\n","        all_outputs.append(outputs)\n","        all_tags.append(b_tags)\n","\n","    all_outputs = torch.cat(all_outputs)\n","    all_tags = torch.cat(all_tags)\n","    \n","    return all_outputs, all_tags"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9HPx3ywdDUj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021812793,"user_tz":-180,"elapsed":31,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"fc9704dd-677a-4054-8242-34ca8cea2504"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uDf2IvsdEeg"},"source":["INPUT_DIM = len(word_to_ix)+1\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 128\n","OUTPUT_DIM = len(tag2num)\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.25\n","PAD_IDX = len(word_to_ix)\n","\n","model = BiLSTMPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n","optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWu61Ea-dKbc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021866335,"user_tz":-180,"elapsed":53567,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"76764d94-e332-4d1b-a5f4-1860f7a30fd9"},"source":["epochs = 50\n","for e in range(epochs):\n","    train_on_epoch(model, dataloader, optimizer)    \n","    \n","    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n","    loss = criterion(all_outputs, all_tags).item()\n","    all_outputs = all_outputs.detach().cpu().numpy()\n","    all_tags = all_tags.detach().cpu().numpy()\n","    \n","    mask = all_tags != pad_inds\n","    loss = loss/len(all_tags[mask]) \n","    all_tags = all_tags[mask]\n","    all_preds = np.argmax(all_outputs, axis=1)[mask]\n","    \n","    print(f\"{e}:\\tLoss {loss}, \"\n","          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n","          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0:\tLoss 5.555995878122253e-06, accuracy: 0.712891381759811, f1-macro: 0.5301255090844345\n","1:\tLoss 3.625042124114271e-06, accuracy: 0.8057774743691458, f1-macro: 0.701348635940512\n","2:\tLoss 2.7352445640857934e-06, accuracy: 0.8542408531522722, f1-macro: 0.766576361015138\n","3:\tLoss 2.1715787720776866e-06, accuracy: 0.8841368536934876, f1-macro: 0.8100879650052405\n","4:\tLoss 1.7596737511776173e-06, accuracy: 0.9073845150894543, f1-macro: 0.8486740188237801\n","5:\tLoss 1.4486268920721072e-06, accuracy: 0.9239838373401723, f1-macro: 0.8748928636731025\n","6:\tLoss 1.182039558227273e-06, accuracy: 0.9393715751213122, f1-macro: 0.900752556225359\n","7:\tLoss 9.74678834569709e-07, accuracy: 0.9506878970706717, f1-macro: 0.9202093180925691\n","8:\tLoss 7.974340416296699e-07, accuracy: 0.9599869616290584, f1-macro: 0.9340762508789933\n","9:\tLoss 6.414872591605942e-07, accuracy: 0.9685849062405826, f1-macro: 0.9472922393708203\n","10:\tLoss 5.343079924736665e-07, accuracy: 0.9743476201897944, f1-macro: 0.9557452791754005\n","11:\tLoss 4.476045453953208e-07, accuracy: 0.9786158416206941, f1-macro: 0.9625945763039189\n","12:\tLoss 3.5387336659025434e-07, accuracy: 0.9837573878976857, f1-macro: 0.9709447732117014\n","13:\tLoss 2.783736962332538e-07, accuracy: 0.9876012472554844, f1-macro: 0.9775215865695849\n","14:\tLoss 2.2864620170915148e-07, accuracy: 0.9901843207439252, f1-macro: 0.9815482210806998\n","15:\tLoss 1.7913686750917537e-07, accuracy: 0.992742793532476, f1-macro: 0.985894118177643\n","16:\tLoss 1.534694416239673e-07, accuracy: 0.9939605281770266, f1-macro: 0.9880049233351306\n","17:\tLoss 1.2967105310920746e-07, accuracy: 0.9949876073974304, f1-macro: 0.9906059790330898\n","18:\tLoss 1.2003313001863792e-07, accuracy: 0.9950368087972102, f1-macro: 0.9914523545255184\n","19:\tLoss 9.603362710299802e-08, accuracy: 0.9961991918670087, f1-macro: 0.99364545726996\n","20:\tLoss 8.063191947549494e-08, accuracy: 0.9967896086643665, f1-macro: 0.9943819354857669\n","21:\tLoss 7.169246110885228e-08, accuracy: 0.9972693223122198, f1-macro: 0.9950813558507046\n","22:\tLoss 6.086122029070943e-08, accuracy: 0.9976014317607336, f1-macro: 0.996397605704501\n","23:\tLoss 4.745043468544112e-08, accuracy: 0.9982533503078163, f1-macro: 0.9966145181545457\n","24:\tLoss 3.558415521231324e-08, accuracy: 0.9987761151804769, f1-macro: 0.9979170329678281\n","25:\tLoss 2.980975706792835e-08, accuracy: 0.9990651734041833, f1-macro: 0.9980648235466851\n","26:\tLoss 2.3466955281320404e-08, accuracy: 0.9992742793532476, f1-macro: 0.9984873782365485\n","27:\tLoss 2.0723140146164615e-08, accuracy: 0.9993603818028622, f1-macro: 0.9990717064249731\n","28:\tLoss 1.8326435224261672e-08, accuracy: 0.9994526344274495, f1-macro: 0.9991993753201053\n","29:\tLoss 1.5750866960057447e-08, accuracy: 0.9996002386267889, f1-macro: 0.9994997773734946\n","30:\tLoss 1.2522339885471364e-08, accuracy: 0.9996555902015413, f1-macro: 0.9993936746798381\n","31:\tLoss 1.3664412447116404e-08, accuracy: 0.9996309895016513, f1-macro: 0.9994749684380302\n","32:\tLoss 1.1728543143725873e-08, accuracy: 0.999717091951266, f1-macro: 0.9996533721147032\n","33:\tLoss 1.0610340459227324e-08, accuracy: 0.999717091951266, f1-macro: 0.9996319462487172\n","34:\tLoss 1.0373420168665607e-08, accuracy: 0.9997109417762935, f1-macro: 0.9996266995442556\n","35:\tLoss 9.369491325969243e-09, accuracy: 0.9997539930011009, f1-macro: 0.9995995934191119\n","36:\tLoss 9.45404076633126e-09, accuracy: 0.9997355424761835, f1-macro: 0.9996712806493446\n","37:\tLoss 9.168988367396463e-09, accuracy: 0.999717091951266, f1-macro: 0.9996766081727941\n","38:\tLoss 8.682409166212725e-09, accuracy: 0.9997232421262385, f1-macro: 0.99965123782376\n","39:\tLoss 7.4404824911835805e-09, accuracy: 0.9997908940509358, f1-macro: 0.9997004731097746\n","40:\tLoss 7.498251617655336e-09, accuracy: 0.9997293923012109, f1-macro: 0.9996405067716313\n","41:\tLoss 7.36166514345886e-09, accuracy: 0.9997478428261284, f1-macro: 0.9997212802738524\n","42:\tLoss 6.445069450364309e-09, accuracy: 0.9997908940509358, f1-macro: 0.9997850791849994\n","43:\tLoss 6.781690635746008e-09, accuracy: 0.9997601431760733, f1-macro: 0.9997014516555592\n","44:\tLoss 5.990312456194969e-09, accuracy: 0.9997908940509358, f1-macro: 0.9996640209498537\n","45:\tLoss 6.2026325755195076e-09, accuracy: 0.9998031944008807, f1-macro: 0.9997443768196623\n","46:\tLoss 6.540483089287196e-09, accuracy: 0.9997662933510458, f1-macro: 0.9997434796785456\n","47:\tLoss 5.188817913551415e-09, accuracy: 0.9998400954507156, f1-macro: 0.9998305808800045\n","48:\tLoss 5.782928981728556e-09, accuracy: 0.9997785937009908, f1-macro: 0.9997328675131302\n","49:\tLoss 6.5554190353909475e-09, accuracy: 0.999741692651156, f1-macro: 0.9996544476673603\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8kcXubKVdVov"},"source":["def count_metrics(model, dataloader):\n","  y_pred, y_true = predict_on_dataloader(model, dataloader)\n","\n","  y_pred = y_pred.detach().cpu().numpy()\n","  y_true = y_true.detach().cpu().numpy()\n","\n","  mask = y_true != pad_inds\n","  y_true = y_true[mask]\n","  y_pred = np.argmax(y_pred, axis=1)[mask]\n","\n","  print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"25kR8EZsdavw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021866917,"user_tz":-180,"elapsed":614,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"79b73bb1-993f-4ef2-fd2f-8d980f292e36"},"source":["count_metrics(model, dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9962\n","           1       1.00      1.00      1.00     13578\n","           2       1.00      1.00      1.00      8547\n","           3       1.00      1.00      1.00     10404\n","           4       1.00      1.00      1.00      5202\n","           5       1.00      1.00      1.00     13014\n","           6       1.00      1.00      1.00       649\n","           7       1.00      1.00      1.00     27080\n","           8       1.00      1.00      1.00      3339\n","           9       1.00      1.00      1.00      4484\n","          10       1.00      1.00      1.00     15619\n","          11       1.00      1.00      1.00     10523\n","          12       1.00      1.00      1.00     16990\n","          13       1.00      1.00      1.00      3134\n","          14       1.00      1.00      1.00       484\n","          15       1.00      1.00      1.00     18849\n","          16       1.00      1.00      1.00       739\n","\n","    accuracy                           1.00    162597\n","   macro avg       1.00      1.00      1.00    162597\n","weighted avg       1.00      1.00      1.00    162597\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VAOUiigWdY7m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625021866919,"user_tz":-180,"elapsed":15,"user":{"displayName":"Виталий Бур","photoUrl":"","userId":"10219767683833213654"}},"outputId":"35f28026-fdda-4b8d-ca95-9ea46ca4cdb1"},"source":["data = TensorDataset(X_test, Y_test)\n","test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n","count_metrics(model, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.83      0.81      1466\n","           1       0.90      0.97      0.93      1656\n","           2       0.85      0.86      0.85      1066\n","           3       0.97      0.97      0.97      1336\n","           4       0.99      0.99      0.99       599\n","           5       0.99      0.99      0.99      1607\n","           6       0.95      0.77      0.85       115\n","           7       0.83      0.87      0.85      3446\n","           8       0.78      0.71      0.74       448\n","           9       0.94      0.96      0.95       546\n","          10       0.97      0.99      0.98      1923\n","          11       0.78      0.67      0.72      1773\n","          12       0.99      0.99      0.99      2467\n","          13       0.92      0.77      0.84       330\n","          14       0.84      0.79      0.82        81\n","          15       0.91      0.89      0.90      2306\n","          16       0.33      0.34      0.33       114\n","\n","    accuracy                           0.90     21279\n","   macro avg       0.87      0.84      0.85     21279\n","weighted avg       0.90      0.90      0.90     21279\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W32kZg1qdbSj"},"source":[""],"execution_count":null,"outputs":[]}]}