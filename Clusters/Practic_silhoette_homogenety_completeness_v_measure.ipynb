{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54715859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "\n",
    "n_samples = 1500\n",
    "dataset = datasets.make_blobs(n_samples=n_samples, centers=2, center_box=(-7.0, 7.5),\n",
    "                              cluster_std=[1.4, 1.7],\n",
    "                              random_state=42)\n",
    "X_2, _ = datasets.make_blobs(n_samples=n_samples, random_state=170, centers=[[-4, -3]], cluster_std=[1.9])\n",
    "transformation = [[1.2, -0.8], [-0.4, 1.7]]\n",
    "X_2 = np.dot(X_2, transformation)\n",
    "X, y = np.concatenate((dataset[0], X_2)), np.concatenate((dataset[1], np.array([2] * len(X_2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf864c6",
   "metadata": {},
   "source": [
    "Коэффициент силуэта можно посчитать при помощи реализации из библиотеки sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d12279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5131209788437305"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# сначала получим предсказанные кластеры при помощи метода кластеризации\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "kmeans_pred = kmeans.labels_\n",
    "\n",
    "# теперь посчитаем коэффициент силуэта\n",
    "silhouette_score(X=X, labels=kmeans_pred, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07555070",
   "metadata": {},
   "source": [
    "В качестве параметров в функции silhouette_score используются:\n",
    "\n",
    "X — массив признаков объектов выборки или массив попарных расстояний между объектами;\n",
    "Y — массив предсказанных кластеров для объектов выборки;\n",
    "metric — метрика, используемая для вычисления расстояния между объектами, мы будем использовать euclidean (Евклидово расстояние)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154f9a1",
   "metadata": {},
   "source": [
    "Задание 7.11.1\n",
    "\n",
    "Обучите модель GaussianMixture с параметрами n_components=3 и random_state=42 на признаках исходного датасета. Посчитайте коэффициент силуэта для получившейся кластеризации. Ответ округлите до десятых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffd458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3131dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = GaussianMixture(n_components=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8ec994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(n_components=3, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194ed381",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = em.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf68a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49893287606943293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считаем коэфф. силуэта\n",
    "silhouette_score(X=X, labels=labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bb30a",
   "metadata": {},
   "source": [
    "Задание 7.11.2\n",
    "\n",
    "Сравните результаты кластеризации четырёх рассмотренных алгоритмов на исходном датасете при помощи коэффициента силуэта, инициализируйте алгоритмы со следующими параметрами:\n",
    "\n",
    "K-means — n_clusters=3, random_state=42\n",
    "EM-алгоритм (GaussianMixture) — n_components=3, random_state=42\n",
    "Агломеративная кластеризация – n_clusters=3\n",
    "DBSCAN – eps=0.9, min_samples=35\n",
    "Укажите максимальное значение коэффициента силуэта, полученное при помощи данных моделей. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c276256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = KMeans(n_clusters=3, random_state=42)\n",
    "em = GaussianMixture(n_components=3, random_state=42)\n",
    "agglomerative = AgglomerativeClustering(n_clusters=3)\n",
    "dbscan = DBSCAN(eps=0.9 ,min_samples=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e391d19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(eps=0.9, min_samples=35)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.fit(X)\n",
    "em.fit(X)\n",
    "agglomerative.fit(X)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6303ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lebels_kmean = kmean.labels_\n",
    "lebels_em = em.predict(X)\n",
    "lebels_agg = agglomerative.labels_\n",
    "lebels_dbscan = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd21dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMean silhouette_score 0.51\n",
      "EM silhouette_score 0.5\n",
      "Agglomerative silhouette_score 0.48\n",
      "DBSCAN silhouette_score 0.45\n"
     ]
    }
   ],
   "source": [
    "print('KMean silhouette_score',round(silhouette_score(X=X, labels=lebels_kmean, metric='euclidean'),2))\n",
    "print('EM silhouette_score',round(silhouette_score(X=X, labels=lebels_em, metric='euclidean'),2))\n",
    "print('Agglomerative silhouette_score',round(silhouette_score(X=X, labels=lebels_agg, metric='euclidean'),2))\n",
    "print('DBSCAN silhouette_score',round(silhouette_score(X=X, labels=lebels_dbscan, metric='euclidean'),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7286e45",
   "metadata": {},
   "source": [
    "Задание 7.11.3\n",
    "\n",
    "Подберите оптимальное количество кластеров с помощью коэффициента силуэта. Для этого найдите такое число кластеров, при котором значение коэффициента будет максимальным.\n",
    "\n",
    "В трёх из рассмотренных нами алгоритмов необходимо задать число кластеров при инициализации: K-means, EM-алгоритм и агломеративная кластеризация.\n",
    "\n",
    "Найдите значение коэффициента силуэта для данных алгоритмов при числе кластеров от 2 до 10 включительно. Для K-means и EM-алгоритма установите значение random_state=42.\n",
    "\n",
    "В качестве ответа через пробел введите число кластеров, при котором значение коэффициента силуэта для результатов кластеризации было наибольшим для каждого из алгоритмов. Вводите в следующем порядке: K-means, EM-алгоритм, агломеративная кластеризация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123ecacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_kmeans = dict()\n",
    "silhouette_em = dict()\n",
    "silhouette_agg = dict()\n",
    "for cluster in range(2,11,1):\n",
    "    \n",
    "    kmean = KMeans(n_clusters=cluster, random_state=42)\n",
    "    em = GaussianMixture(n_components=cluster, random_state=42)\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=cluster)\n",
    "\n",
    "    kmean.fit(X)\n",
    "    em.fit(X)\n",
    "    agglomerative.fit(X)\n",
    "\n",
    "    lebels_kmean = kmean.labels_\n",
    "    lebels_em = em.predict(X)\n",
    "    lebels_agg = agglomerative.labels_\n",
    "    \n",
    "    silhouette_kmeans.update({cluster: round(silhouette_score(X=X, labels=lebels_kmean, metric='euclidean'),3)})\n",
    "    silhouette_em.update({cluster: round(silhouette_score(X=X, labels=lebels_em, metric='euclidean'),3)})\n",
    "    silhouette_agg.update({cluster: round(silhouette_score(X=X, labels=lebels_agg, metric='euclidean'),3)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e6da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластер с наибольшим коэффициентом силуэта KMeans 3\n",
      "Кластер с наибольшим коэффициентом силуэта EM 4\n",
      "Кластер с наибольшим коэффициентом силуэта Agglomerative 4\n"
     ]
    }
   ],
   "source": [
    "print('Кластер с наибольшим коэффициентом силуэта KMeans',max(silhouette_kmeans, key=lambda k: silhouette_kmeans[k]))\n",
    "print('Кластер с наибольшим коэффициентом силуэта EM',max(silhouette_em, key=lambda k: silhouette_em[k]))\n",
    "print('Кластер с наибольшим коэффициентом силуэта Agglomerative',max(silhouette_agg, key=lambda k: silhouette_agg[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baaa071",
   "metadata": {},
   "source": [
    "# Однородность. Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f85ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# сначала получим предсказанные кластеры при помощи метода кластеризации\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "kmeans.fit(X); kmeans_pred = kmeans.labels_ # теперь посчитаем однородность homogeneity_score(labels_true=y, labels_pred=kmeans_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8595ee",
   "metadata": {},
   "source": [
    "Задание 7.12.1\n",
    "\n",
    "Сравните результаты кластеризации алгоритмов k-means, GaussianMixture, AgglomerativeClustering и DBSCAN на исходном датасете при помощи однородности, инициализируйте алгоритмы со следующими параметрами:\n",
    "\n",
    "k-means — n_clusters=3, random_state=42\n",
    "GaussianMixture — n_components=3, random_state=42\n",
    "AgglomerativeClustering — n_clusters=3\n",
    "DBSCAN — eps=0.9, min_samples=35\n",
    "В качестве ответа укажите максимальное значение однородности, полученное при помощи данных моделей. Ответ округлите до сотых и запишите с точкой.\n",
    "\n",
    "При решении задания модуля стандартизация должна быть включена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650ac6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "em = GaussianMixture(n_components=3, random_state=42)\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "dbscan = DBSCAN(eps=0.9, min_samples=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b58aad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(eps=0.9, min_samples=35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X)\n",
    "em.fit(X)\n",
    "agg.fit(X)\n",
    "dbscan.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "721599dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_k = kmeans.labels_\n",
    "labels_em = em.predict(X)\n",
    "labels_agg = agg.labels_\n",
    "labels_dbscan = dbscan.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20f2a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полнота KMean 0.8\n",
      "Полнота EM 0.93\n",
      "Полнота Agglomerative 0.91\n",
      "Полнота DBSCAN 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Полнота KMean',round(homogeneity_score(y, labels_k), 2))\n",
    "print('Полнота EM',round(homogeneity_score(y, labels_em), 2))\n",
    "print('Полнота Agglomerative',round(homogeneity_score(y, labels_agg), 2))\n",
    "print('Полнота DBSCAN',round(homogeneity_score(y, labels_dbscan),2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0d01f",
   "metadata": {},
   "source": [
    "# Полнота. Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a3a5e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808712092278982"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "\n",
    "# сначала получим предсказанные кластеры при помощи метода кластеризации\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "kmeans_pred = kmeans.labels_\n",
    "\n",
    "# теперь посчитаем полноту\n",
    "completeness_score(labels_true=y, labels_pred=kmeans_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352dc9cc",
   "metadata": {},
   "source": [
    "Задание 7.13.1\n",
    "\n",
    "Обучите модель GaussianMixture с параметрами n_components = 3 и random_state = 42 на признаках исходного датасета. Посчитайте полноту для получившейся кластеризации. Ответ округлите до сотых и запишите с точкой. Не забудьте о стандартизации, она должна быть включена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "433f660c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = GaussianMixture(n_components=3, random_state=42)\n",
    "em.fit(X)\n",
    "labels_agg = em.predict(X)\n",
    "round(completeness_score(y, labels_agg), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ff07f",
   "metadata": {},
   "source": [
    "Задание 7.13.2\n",
    "\n",
    "Сравните результаты кластеризации алгоритмов k-means, GaussianMixture, AgglomerativeClustering и DBSCAN на исходном датасете при помощи полноты, инициализируйте алгоритмы со следующими параметрами:\n",
    "\n",
    "k-means — n_clusters=3, random_state=42\n",
    "GaussianMixture — n_components=3, random_state=42\n",
    "AgglomerativeClustering — n_clusters=3\n",
    "DBSCAN — eps=0.9, min_samples=35\n",
    "В качестве ответа укажите максимальное значение полноты, полученное при помощи данных моделей.\n",
    "\n",
    "Подсказка: При решении задания модуля стандартизация должна быть включена. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b5bdf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = KMeans(n_clusters=3, random_state=42)\n",
    "em = GaussianMixture(n_components=3, random_state=42)\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "dbscan = DBSCAN(eps=0.9, min_samples=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac99ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(eps=0.9, min_samples=35)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.fit(X)\n",
    "em.fit(X)\n",
    "agg.fit(X)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed121d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_k = kmean.labels_\n",
    "labels_em = em. predict(X)\n",
    "labels_agg = agg.labels_\n",
    "labels_dbscan = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b575218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полнота KMeans 0.78\n",
      "Полнота EM 0.93\n",
      "Полнота Agglomerative 0.91\n",
      "Полнота DBSCAN 0.08\n"
     ]
    }
   ],
   "source": [
    "print('Полнота KMeans', round(completeness_score(y, labels_k),2))\n",
    "print('Полнота EM',round(completeness_score(y, labels_em),2))\n",
    "print('Полнота Agglomerative',round(completeness_score(y, labels_agg),2))\n",
    "print('Полнота DBSCAN',round(completeness_score(y, labels_dbscan),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4633842",
   "metadata": {},
   "source": [
    "# V-мера. Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84a7209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.791546668267586"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "# сначала получим предсказанные кластеры при помощи метода кластеризации\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "kmeans_pred = kmeans.labels_\n",
    "\n",
    "# теперь посчитаем полноту\n",
    "v_measure_score(labels_true=y, labels_pred=kmeans_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b50f9",
   "metadata": {},
   "source": [
    "Задание 7.14.1\n",
    "Обучите модель GaussianMixture с параметрами n_components=3 и random_state=42 на признаках исходного датасета. Посчитайте v-меру для получившейся кластеризации.\n",
    "\n",
    "Подсказка: При решении задания модуля стандартизация должна быть включена. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee383e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure 0.93\n"
     ]
    }
   ],
   "source": [
    "em = GaussianMixture(n_components=3, random_state=42)\n",
    "em.fit(X)\n",
    "labels_em = em.predict(X)\n",
    "print('V_measure',round(v_measure_score(y, labels_em),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae86395",
   "metadata": {},
   "source": [
    "Задание 7.14.2\n",
    "Сравните результаты кластеризации алгоритмов k-means, GaussianMixture, AgglomerativeClustering и DBSCAN на исходном датасете при помощи v-меры, инициализируйте алгоритмы со следующими параметрами:\n",
    "\n",
    "k-means — n_clusters=3, random_state=42\n",
    "GaussianMixture — n_components=3, random_state=42\n",
    "AgglomerativeClustering — n_clusters=3\n",
    "DBSCAN — eps=0.9, min_samples=35\n",
    "В качестве ответа укажите максимальное значение v-меры, полученное при помощи данных моделей. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4f2a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "em = GaussianMixture(n_components=3, random_state=42)\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "dbscan = DBSCAN(eps=0.9, min_samples=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "870a7676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(eps=0.9, min_samples=35)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X)\n",
    "em.fit(X)\n",
    "agg.fit(X)\n",
    "dbscan.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f1001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_k = kmeans.labels_\n",
    "labels_em = em.predict(X)\n",
    "labels_agg = agg.labels_\n",
    "labels_dbscan = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ef69562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure KMeans 0.79\n",
      "V_measure EM 0.93\n",
      "V_measure Agglomerative 0.91\n",
      "V_measure DBSCAN 0.0\n"
     ]
    }
   ],
   "source": [
    "print('V_measure KMeans', round(v_measure_score(y, labels_k),2))\n",
    "print('V_measure EM',round(v_measure_score(y, labels_em),2))\n",
    "print('V_measure Agglomerative',round(v_measure_score(y, labels_agg),2))\n",
    "print('V_measure DBSCAN',round(v_measure_score(y, labels_dbscan),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391dac2",
   "metadata": {},
   "source": [
    "Задание 7.14.3\n",
    "Сравним модификации K-means с использованием случайной инициализации центроид и с использованием алгоритма K-means++ для инициализации центроид.\n",
    "\n",
    "Для этого обучим на исходном датасете 2 модели k-means со следующими параметрами:\n",
    "\n",
    "n_clusters=3, init='k-means++', n_init=1, random_state=42\n",
    "n_clusters=3, init='random', n_init=1, random_state=42\n",
    "В качестве ответа укажите максимальное значение v-меры, полученное при помощи данных моделей.\n",
    "\n",
    "Подсказка: При решении задания модуля стандартизация должна быть включена. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f920713",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_plus = KMeans(n_clusters=3, init='k-means++',n_init=1, random_state=42)\n",
    "kmeans_random = KMeans(n_clusters=3, init='random', n_init=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "957b10bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=3, n_init=1, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_plus.fit(X)\n",
    "kmeans_random.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d06158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_k_plus = kmeans_plus.labels_\n",
    "labels_k_random = kmeans_random.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b50b5edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure_k++ 0.79\n",
      "V_measure_random 0.79\n"
     ]
    }
   ],
   "source": [
    "print('V_measure_k++',round(v_measure_score(y, labels_k_plus),2))\n",
    "print('V_measure_random',round(v_measure_score(y, labels_k_random),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b3d88",
   "metadata": {},
   "source": [
    "Задание 7.14.4\n",
    "Теперь сравним k-means с ещё одной модификацией — K-means mini batch. Воспользоваться реализацией K-means mini batch в библиотеке sklearn можно следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e5dd0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetak\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 2048 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "kmeans_mini_batch = MiniBatchKMeans(n_clusters=\n",
    "3, random_state=\n",
    "42)\n",
    "kmeans_mini_batch.fit(X)\n",
    "kmeans_mini_batch_pred = kmeans_mini_batch.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037ffd3",
   "metadata": {},
   "source": [
    "Механизм кластеризации версии K-means mini batch схож с оригинальной версией алгоритма. Обучите на исходном датасете две модели:\n",
    "\n",
    "k-means с параметрами n_clusters=3, n_init=1, random_state=42\n",
    "MiniBatchKMeans с параметрами n_clusters=3, n_init=1, random_state=42\n",
    "В качестве ответа введите максимальное значение v-меры, полученное при помощи данных моделей. В задании может понадобиться, а может не понадобиться нормализация и это нужно проверить во время решения задания. Ответ округлите до десятых и запишите с точкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01eabc",
   "metadata": {},
   "source": [
    "## С нормализацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c50ca492",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, n_init=1, random_state=42)\n",
    "kmeans_mini_batch = MiniBatchKMeans(n_clusters=3, n_init=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "692245b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetak\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 2048 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(n_clusters=3, n_init=1, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X)\n",
    "kmeans_mini_batch.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33a03740",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_k = kmeans.labels_\n",
    "labels_mini_batch = kmeans_mini_batch.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "290d6cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure_kmean 0.8\n",
      "V_measure_mini_batch 0.7\n"
     ]
    }
   ],
   "source": [
    "print('V_measure_kmean',round(v_measure_score(y, labels_k),1))\n",
    "print('V_measure_mini_batch',round(v_measure_score(y, labels_mini_batch),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcb563",
   "metadata": {},
   "source": [
    "##  Без нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc36a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "dataset = datasets.make_blobs(n_samples=n_samples, centers=2, center_box=(-7.0, 7.5),\n",
    "                              cluster_std=[1.4, 1.7],\n",
    "                              random_state=42)\n",
    "X_2, _ = datasets.make_blobs(n_samples=n_samples, random_state=170, centers=[[-4, -3]], cluster_std=[1.9])\n",
    "transformation = [[1.2, -0.8], [-0.4, 1.7]]\n",
    "X_2 = np.dot(X_2, transformation)\n",
    "X, y = np.concatenate((dataset[0], X_2)), np.concatenate((dataset[1], np.array([2] * len(X_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96170cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure_kmean 0.8\n",
      "V_measure_mini_batch 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetak\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 2048 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, n_init=1, random_state=42)\n",
    "kmeans_mini_batch = MiniBatchKMeans(n_clusters=3, n_init=1, random_state=42)\n",
    "\n",
    "kmeans.fit(X)\n",
    "kmeans_mini_batch.fit(X)\n",
    "\n",
    "labels_k = kmeans.labels_\n",
    "labels_mini_batch = kmeans_mini_batch.labels_\n",
    "\n",
    "print('V_measure_kmean',round(v_measure_score(y, labels_k),1))\n",
    "print('V_measure_mini_batch',round(v_measure_score(y, labels_mini_batch),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285f2d4",
   "metadata": {},
   "source": [
    "Задание 7.14.5\n",
    "Рассмотрим агломеративную кластеризацию. Сравним, как влияет на качество кластеризации разный тип расстояния между кластерами.\n",
    "\n",
    "Обучите на исходном датасете четыре модели AgglomerativeClustering с параметром n_clusters=3, меняя параметр linkage.\n",
    "\n",
    "В качестве ответа укажите максимальное значение v-меры, полученное при помощи данных моделей. В задании может понадобиться, а может не понадобиться нормализация и это нужно проверить во время решения задания. Ответ округлите до десятых и запишите с точкой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce7090",
   "metadata": {},
   "source": [
    "## Без нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d3bce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ward': 0.7, 'complete': 0.4, 'average': 0.5, 'single': 0.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_linkage = dict()\n",
    "list_linkage = ['ward', 'complete', 'average', 'single']\n",
    "\n",
    "for link in list_linkage:\n",
    "    model = AgglomerativeClustering(n_clusters=3, linkage=link)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "    dict_linkage.update({link: round(v_measure_score(y, labels),1)})\n",
    "    \n",
    "dict_linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed3583",
   "metadata": {},
   "source": [
    "## С нормализацей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70f02426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ward': 0.9, 'complete': 0.6, 'average': 0.7, 'single': 0.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "dict_linkage = dict()\n",
    "list_linkage = ['ward', 'complete', 'average', 'single']\n",
    "\n",
    "for link in list_linkage:\n",
    "    model = AgglomerativeClustering(n_clusters=3, linkage=link)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "    dict_linkage.update({link: round(v_measure_score(y, labels),1)})\n",
    "    \n",
    "dict_linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0899c",
   "metadata": {},
   "source": [
    "Задание 7.14.6\n",
    "Сравним, как влияет предварительный расчёт матрицы смежности на качество агломеративной кластеризации.\n",
    "\n",
    "Обучите на исходном датасете две модели AgglomerativeClustering:\n",
    "\n",
    "с параметром n_clusters=3\n",
    "с параметром n_clusters=3 и предварительно посчитанной матрицей смежности для объектов датасета\n",
    "Построить матрицу смежности можно с помощью кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb4596ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "connectivity = kneighbors_graph(X, n_neighbors=\n",
    "6, include_self=\n",
    "False)\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8582942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure Agglometative_common 0.91\n",
      "V_measure_Agglomerative_connectivity 0.88\n"
     ]
    }
   ],
   "source": [
    "agg_common = AgglomerativeClustering(n_clusters=3)\n",
    "agg_connectivity = AgglomerativeClustering(n_clusters=3, connectivity=connectivity)\n",
    "\n",
    "agg_common.fit(X)\n",
    "agg_connectivity.fit(X)\n",
    "\n",
    "labels_agg_common = agg_common.labels_\n",
    "labels_agg_connectivity = agg_connectivity.labels_\n",
    "\n",
    "print('V_measure Agglometative_common',round(v_measure_score(y, labels_agg_common),2))\n",
    "print('V_measure_Agglomerative_connectivity',round(v_measure_score(y, labels_agg_connectivity),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd393e75",
   "metadata": {},
   "source": [
    "Задание 7.14.7\n",
    "Алгоритм DBSCAN очень требователен к параметрам: небольшое изменение в параметре eps или min_samples может изменить результат и качество кластеризации.\n",
    "\n",
    "Обучите на исходном датасете две модели DBSCAN:\n",
    "\n",
    "с параметрами eps=0.9, min_samples=35\n",
    "с параметрами eps=0.8, min_samples=35\n",
    "В качестве ответа укажите максимальное значение v-меры, полученное при помощи данных моделей. В задании может понадобиться, а может не понадобиться нормализация и это нужно проверить во время решения задания. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08de063",
   "metadata": {},
   "source": [
    "## Без нормализации \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e5d301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_samples = 1500\n",
    "dataset = datasets.make_blobs(n_samples=n_samples, centers=2, center_box=(-7.0, 7.5),\n",
    "                              cluster_std=[1.4, 1.7],\n",
    "                              random_state=42)\n",
    "X_2, _ = datasets.make_blobs(n_samples=n_samples, random_state=170, centers=[[-4, -3]], cluster_std=[1.9])\n",
    "transformation = [[1.2, -0.8], [-0.4, 1.7]]\n",
    "X_2 = np.dot(X_2, transformation)\n",
    "X, y = np.concatenate((dataset[0], X_2)), np.concatenate((dataset[1], np.array([2] * len(X_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63c21847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure DBSCAN 0.9 0.77\n",
      "V_measure DBSCAN 0.8 0.71\n"
     ]
    }
   ],
   "source": [
    "dbscan_0 = DBSCAN(eps=0.9, min_samples=35)\n",
    "dbscan_1 = DBSCAN(eps=0.8, min_samples=35)\n",
    "\n",
    "dbscan_0.fit(X)\n",
    "dbscan_1.fit(X)\n",
    "\n",
    "labels_0 = dbscan_0.labels_\n",
    "labels_1 = dbscan_1.labels_\n",
    "\n",
    "print('V_measure DBSCAN 0.9',round(v_measure_score(y, labels_0),2))\n",
    "print('V_measure DBSCAN 0.8',round(v_measure_score(y, labels_1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431f303",
   "metadata": {},
   "source": [
    "# С Нормализацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b84904b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure DBSCAN 0.9 0.0\n",
      "V_measure DBSCAN 0.8 0.0\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "dbscan_0 = DBSCAN(eps=0.9, min_samples=35)\n",
    "dbscan_1 = DBSCAN(eps=0.8, min_samples=35)\n",
    "\n",
    "dbscan_0.fit(X)\n",
    "dbscan_1.fit(X)\n",
    "\n",
    "labels_0 = dbscan_0.labels_\n",
    "labels_1 = dbscan_1.labels_\n",
    "\n",
    "print('V_measure DBSCAN 0.9',round(v_measure_score(y, labels_0),2))\n",
    "print('V_measure DBSCAN 0.8',round(v_measure_score(y, labels_1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefeac38",
   "metadata": {},
   "source": [
    "# ВЫВОД НА DBSCAN НОРМАЛИЗАЦИЯ НЕ НУЖНА"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ef461",
   "metadata": {},
   "source": [
    "Задание 7.14.8\n",
    "\n",
    "Особенностью алгоритма DBSCAN является то, что помимо кластеризации этот алгоритм определяет выбросы в выборке. Посмотрим на качество кластеризации без учёта таких объектов.\n",
    "\n",
    "Обучите на исходном датасете модель DBSCAN с параметрами eps=0.9, min_samples=35. Посчитайте значение v-меры только для основных и граничных объектов выборки, то есть для объектов, что не являются выбросами. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74711139",
   "metadata": {},
   "source": [
    "# Без нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "091ecf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = StandardScaler().fit_transform(X)\n",
    "X, y = np.concatenate((dataset[0], X_2)), np.concatenate((dataset[1], np.array([2] * len(X_2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dbd54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.9, min_samples=35)\n",
    "dbscan.fit(X)\n",
    "labels_dbscan = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "277be9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_noise_ind = np.where(labels_dbscan != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10c8efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure DBSCAN без выбросов 0.97\n"
     ]
    }
   ],
   "source": [
    "print('V_measure DBSCAN без выбросов', round((v_measure_score(y[not_noise_ind], labels_dbscan[not_noise_ind])),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b6398",
   "metadata": {},
   "source": [
    "Задание 7.14.9\n",
    "В курсе мы рассмотрели две метода нормализации данных:\n",
    "\n",
    "MinMax нормализация — приведение данных к масштабу между  и .\n",
    "Стандартная нормализация — данные имеют среднее  и стандартное отклонение .\n",
    "Проверим, влияет ли предобработка данных на результат кластеризации. Обучите две модели AgglomerativeClustering с параметрами n_clusters=3:\n",
    "\n",
    "на признаках исходного датасета,\n",
    "предварительно трансформируйте признаки при помощи стандартной нормализации.\n",
    "Посчитайте v-меру для получившихся результатов, в качестве ответа введите наибольшее значение. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42fddc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure Agglomerative common 0.7\n",
      "V_measure Agglomerative standart 0.91\n"
     ]
    }
   ],
   "source": [
    "agg_0 = AgglomerativeClustering(n_clusters=3) # без нормализации\n",
    "agg_1 = AgglomerativeClustering(n_clusters=3) # с стандартной нормализацией\n",
    "\n",
    "labels_0 = agg_0.fit_predict(X)\n",
    "labels_1 = agg_1.fit_predict(X_norm)\n",
    "\n",
    "print('V_measure Agglomerative common',round(v_measure_score(y, labels_0),2))\n",
    "print('V_measure Agglomerative standart',round(v_measure_score(y, labels_1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefeb56c",
   "metadata": {},
   "source": [
    "Задание 7.14.10\n",
    "Обучите две модели AgglomerativeClustering с параметрами n_clusters=3:\n",
    "\n",
    "на признаках исходного датасета,\n",
    "предварительно трансформируйте признаки при помощи MinMax нормализации.\n",
    "Посчитайте v-меру для получившихся результатов, в качестве ответа введите наибольшее значение. Ответ округлите до сотых и запишите с точкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c0e348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa6b63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minmax = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "359712ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_measure Agglomerative common 0.7\n",
      "V_measure Agglomerative minmax 0.89\n"
     ]
    }
   ],
   "source": [
    "agg_0 = AgglomerativeClustering(n_clusters=3) # без нормализации\n",
    "agg_1 = AgglomerativeClustering(n_clusters=3) # с нормализацией MinMax\n",
    "\n",
    "labels_0 = agg_0.fit_predict(X)\n",
    "labels_1 = agg_1.fit_predict(X_minmax)\n",
    "\n",
    "print('V_measure Agglomerative common',round(v_measure_score(y, labels_0),2))\n",
    "print('V_measure Agglomerative minmax',round(v_measure_score(y, labels_1),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c11e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4710d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1554e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
