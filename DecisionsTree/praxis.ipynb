{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dd32fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score, plot_roc_curve\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, plot_precision_recall_curve\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffe6e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(report_df, model, X_test, y_test, name):\n",
    "    '''Create and add metrics into a pandas DF after experiment'''\n",
    "\n",
    "    report = pd.DataFrame(columns={'ROC-AUC'}, data=[0])\n",
    "    report['ROC-AUC'] = roc_auc_score(y_test,\n",
    "                                      model.predict_proba(X_test)[:, 1])\n",
    "    report['PR-AUC'] = precision_score(y_test,model.predict(X_test))\n",
    "    report['F1'] = f1_score(y_test, model.predict(X_test))\n",
    "    report['precision_Neg'] = precision_score(\n",
    "        y_test, model.predict(X_test), pos_label=0)\n",
    "    report['precision_Pos'] = precision_score(\n",
    "        y_test, model.predict(X_test), pos_label=1)\n",
    "    report['recall_Neg'] = recall_score(\n",
    "        y_test, model.predict(X_test), pos_label=0)\n",
    "    report['recall_Pos'] = recall_score(\n",
    "        y_test, model.predict(X_test), pos_label=1)\n",
    "\n",
    "    report.index = [name]\n",
    "    report_df = report_df.append(report)\n",
    "    return report_df\n",
    "\n",
    "\n",
    "df_report = pd.DataFrame(data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebdce335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HR-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a61a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
      "       'average_montly_hours', 'time_spend_company', 'Work_accident',\n",
      "       'promotion_last_5years', 'dept', 'salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "target = 'left'\n",
    "features = df.columns.drop(target)\n",
    "# Удалим идентификатор пользователя как нерепрезентативный признак\n",
    "features = features.drop('empid')\n",
    "print(features)\n",
    "\n",
    "X, y = df[features].copy(), df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "414f43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_ordinals = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "X['dept'] = X['dept'].apply(X['dept'].value_counts().get)\n",
    "X['salary'] = X['salary'].apply(salary_ordinals.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c58cf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88171d6",
   "metadata": {},
   "source": [
    "В дальнейшем будем оценивать качество модели на кросс-валидации на пяти фолдах при помощи точности (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be8e8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(clf, X, y, cv=5):\n",
    "    return cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab06beb",
   "metadata": {},
   "source": [
    "Бэггинг (bagging, сокр. от bootstrap aggregating)  — метод построения композиции алгоритмов, в котором каждый алгоритм строится независимо от других на подвыборках обучающей выборки. Итоговый алгоритм принимает решения посредством голосования среди всех алгоритмов (возвращается самый частый ответ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4824c3d",
   "metadata": {},
   "source": [
    "Посмотрим на точность одного дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97abd798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.9731310659108592\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=30)\n",
    "print(\"Decision tree:\", estimate_accuracy(tree, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e24754",
   "metadata": {},
   "source": [
    "Проведём бэггинг: для этого достаточно обернуть исходный классификатор в BaggingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04d5fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree bagging: 0.9880660886962321\n"
     ]
    }
   ],
   "source": [
    "bagging_trees = BaggingClassifier(tree)\n",
    "print(\"Decision tree bagging:\", estimate_accuracy(bagging_trees, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36689805",
   "metadata": {},
   "source": [
    "Увеличить различность построенных деревьев можно, указав параметры max_features и max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3128d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tree: 0.9778657330221184\n"
     ]
    }
   ],
   "source": [
    "random_tree = DecisionTreeClassifier(max_features=int(np.sqrt(len(features))), max_depth=30)\n",
    "print(\"Random tree:\", estimate_accuracy(random_tree, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e5896f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tree bagging: 0.9902662443036567\n"
     ]
    }
   ],
   "source": [
    "bagging_random_trees = BaggingClassifier(random_tree)\n",
    "print(\"Random tree bagging:\", estimate_accuracy(bagging_random_trees, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640e430",
   "metadata": {},
   "source": [
    "**Стандартная эвристика: в задаче классификации брать квадратный корень числа признаков, а в задаче регрессии — треть числа признаков.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "798c509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.9920663109925532\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    max_features=int(np.sqrt(len(features))),\n",
    "    max_depth=30)\n",
    "print(\"Random Forest:\", estimate_accuracy(random_forest, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e64d04",
   "metadata": {},
   "source": [
    "Ещё одно преимущество использования бэггинга для аггрегации моделей — получение оценки работы классификатора без дополнительного проведения кросс-валидации при помощи out-of-bag score. Это метод вычисления произвольной оценки качества во время обучения бэггинга. Для подсчёта требуется указать параметр oob_score = True, что имеет смысл при достаточном количестве деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe050881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929995333022201"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=int(np.sqrt(len(features))),\n",
    "    max_depth=30,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_forest.fit(X, y)\n",
    "random_forest.oob_score_.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5359ba",
   "metadata": {},
   "source": [
    "Метод бэггинга можно применять к произвольным алгоритмам, например, к логистической регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04bf3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.7709770367900411\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='saga', max_iter=200)\n",
    "lr.fit(X, y)\n",
    "print(\"LR:\", estimate_accuracy(lr, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c469777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging for LR: 0.7701104368122708\n"
     ]
    }
   ],
   "source": [
    "random_logreg = BaggingClassifier(\n",
    "    lr,\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58405686",
   "metadata": {},
   "source": [
    "В её случае он не так сильно повышает качество, поскольку линейные модели не так сильно зависят от состава обучающей выборки. Попробуем убрать часть признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "718e8927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging for LR: 0.7569754140268978\n"
     ]
    }
   ],
   "source": [
    "random_logreg = BaggingClassifier(\n",
    "    lr,\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1,\n",
    "    max_features=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea476c40",
   "metadata": {},
   "source": [
    "Сравнение логистической регрессии и случайного леса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b213e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(X, y, clf, proba=False, points_size=7, xlabel='x', ylabel='y'):\n",
    "    \"\"\"Fits the classifier on the data (X, y) and plots the result on a 2-D plane.\"\"\"\n",
    "    def get_grid(data):\n",
    "        x_std, y_std = data.std(axis=0)\n",
    "        x_min, x_max = data[:, 0].min() - x_std / 2, data[:, 0].max() + x_std / 2\n",
    "        y_min, y_max = data[:, 1].min() - y_std / 2, data[:, 1].max() + y_std / 2\n",
    "        return np.meshgrid(np.linspace(x_min, x_max, num=200),\n",
    "                           np.linspace(y_min, y_max, num=200))\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    xx, yy = get_grid(X)\n",
    "    if proba:\n",
    "        predicted = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1].reshape(xx.shape)\n",
    "    else:\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "    plt.figure(figsize=(10.0, 10.0))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap=plt.cm.coolwarm, alpha=0.1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=points_size, cmap=plt.cm.coolwarm, alpha=0.90)\n",
    "    plt.ylim([yy.min(),yy.max()])\n",
    "    plt.xlim([xx.min(),xx.max()])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3ef6b",
   "metadata": {},
   "source": [
    "# ПРАКТИКА\n",
    "1. Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits). \n",
    "2. Информацию о датасете вы можете получить, обратившись к полю DESCR у возвращаемого объекта load_digits. Нам предстоит решать задачу классификации изображений с цифрами по численным признакам.\n",
    "3. Для оценки качества мы будем использовать cross_val_score из sklearn.model_selection с параметром cv = 10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Предлагается использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел — качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30adc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd39fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e1af215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=df.data, columns=df.feature_names)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fcb0a0",
   "metadata": {},
   "source": [
    "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f573b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "# dtc.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f7a03d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235723153320919"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dtc,X,y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c38c9",
   "metadata": {},
   "source": [
    "Теперь давайте обучим BaggingClassifier на основе DecisionTreeClassifier. Из sklearn.ensemble импортируйте BaggingClassifier, все параметры задайте по умолчанию. Нужно изменить только количество базовых моделей, задав его равным 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66441e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg = BaggingClassifier(base_estimator=dtc, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eff4f485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214990689013035"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bagg,X,y,cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c42e5c",
   "metadata": {},
   "source": [
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался на корне их кол-ва признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba499062",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_ = BaggingClassifier(base_estimator=dtc,n_estimators=100,max_features=int(np.sqrt(len(X.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47e60a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332184978274363"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bagg_,X, y, cv=10, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98410cc",
   "metadata": {},
   "source": [
    " В предыдущем пункте мы выбирали подмножество один раз для каждого очередного дерева. Следующим нашим шагом будет построение бэггинга на основе деревьев, которые выбирают случайное подможество признаков для каждой вершины дерева.\n",
    "\n",
    "Для этого нам потребуется перенести отвечающий за это параметр из BaggingClassifier в DecisionTreeClassifier. Для этого вам из документации нужно выяснить, какой параметр DecisionTreeClassifier за это отвечает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3581d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_ = DecisionTreeClassifier(max_features=int(np.sqrt(len(X.columns))))\n",
    "bagg_n = BaggingClassifier(base_estimator=dtc_, n_estimators=100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "153b0e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9493451272501551"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bagg_n,X, y, cv=10, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18a30fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth =5,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "87096f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075977653631286"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf,X, y, cv=10, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca53383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
